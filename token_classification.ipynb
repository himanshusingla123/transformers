{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec03a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee82572",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4121b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3664ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word , label in zip(words , labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word) , len(full_label))\n",
    "    # to give gap between words such that one comes exactly below of other\n",
    "    line1 += word + \" \" * (max_length - len(word)+1)\n",
    "    line2 += word + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3972f30c",
   "metadata": {},
   "source": [
    "1. You can replace the model_checkpoint with any other model you prefer from the Hub, or with a local folder in which you‚Äôve saved a pretrained model and a tokenizer. \n",
    "2. The only constraint is that the tokenizer needs to be backed by the ü§ó Tokenizers library, so there‚Äôs a ‚Äúfast‚Äù version available. \n",
    "3. You can see all the architectures that come with a fast version in this big table, and to check that the tokenizer object you‚Äôre using is indeed backed by ü§ó Tokenizers you can look at its is_fast attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc207d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718adf8",
   "metadata": {},
   "source": [
    "1. Our function added the -100 for the two special tokens at the beginning and the end, and a new 0 for our word that was split into two tokens.\n",
    "2. This is because by default -100 is an index that is ignored in the loss function we will use (cross entropy). \n",
    "3. Then, each token gets the same label as the token that started the word it‚Äôs inside, since they are part of the same entity. \n",
    "4. For tokens inside a word but not at the beginning, we replace the B- with I- (since the token does not begin the entity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf267a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68a905",
   "metadata": {},
   "source": [
    "1. To preprocess our whole dataset, we need to tokenize all the inputs and apply align_labels_with_tokens() on all the labels. \n",
    "2. To take advantage of the speed of our fast tokenizer, it‚Äôs best to tokenize lots of texts at the same time, so we‚Äôll write a function that processes a list of examples and use the Dataset.map() method with the option batched=True. \n",
    "3. The only thing that is different from our previous example is that the word_ids() function needs to get the index of the example we want the word IDs of when the inputs to the tokenizer are lists of texts (or in our case, list of lists of words), so we add that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d6b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True , is_split_into_words = True\n",
    "    )\n",
    "\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels , word_ids))\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296bac1b",
   "metadata": {},
   "source": [
    "We can now apply all that preprocessing in one go on the other splits of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57454d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785501f",
   "metadata": {},
   "source": [
    "Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f90bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f06d5a",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e6f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e5188",
   "metadata": {},
   "source": [
    "This metric does not behave like the standard accuracy: it will actually take the lists of labels as strings, not integers, so we will need to fully decode the predictions and labels before passing them to the metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038658fb",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68084de6",
   "metadata": {},
   "source": [
    "They should be set by two dictionaries, id2label and label2id, which contain the mappings from ID to label and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44745cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a867ab",
   "metadata": {},
   "source": [
    "let‚Äôs double-check that our model has the right number of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8729b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5709aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
